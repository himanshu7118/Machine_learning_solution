{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={\"figure.figsize\":(30,15)})\n",
    "pd.pandas.set_option(\"display.max_columns\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/ml_assignment_code/ml_assignment_code/data/ObesityDataSet_raw_and_data_sinthetic.csv')\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2111, 17)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2111 entries, 0 to 2110\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Gender                          2111 non-null   object \n",
      " 1   Age                             2111 non-null   float64\n",
      " 2   Height                          2111 non-null   float64\n",
      " 3   Weight                          2111 non-null   float64\n",
      " 4   family_history_with_overweight  2111 non-null   object \n",
      " 5   FAVC                            2111 non-null   object \n",
      " 6   FCVC                            2111 non-null   float64\n",
      " 7   NCP                             2111 non-null   float64\n",
      " 8   CAEC                            2111 non-null   object \n",
      " 9   SMOKE                           2111 non-null   object \n",
      " 10  CH2O                            2111 non-null   float64\n",
      " 11  SCC                             2111 non-null   object \n",
      " 12  FAF                             2111 non-null   float64\n",
      " 13  TUE                             2111 non-null   float64\n",
      " 14  CALC                            2111 non-null   object \n",
      " 15  MTRANS                          2111 non-null   object \n",
      " 16  NObeyesdad                      2111 non-null   object \n",
      "dtypes: float64(8), object(9)\n",
      "memory usage: 280.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24.312600</td>\n",
       "      <td>1.701677</td>\n",
       "      <td>86.586058</td>\n",
       "      <td>2.419043</td>\n",
       "      <td>2.685628</td>\n",
       "      <td>2.008011</td>\n",
       "      <td>1.010298</td>\n",
       "      <td>0.657866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.345968</td>\n",
       "      <td>0.093305</td>\n",
       "      <td>26.191172</td>\n",
       "      <td>0.533927</td>\n",
       "      <td>0.778039</td>\n",
       "      <td>0.612953</td>\n",
       "      <td>0.850592</td>\n",
       "      <td>0.608927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.947192</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>65.473343</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.658738</td>\n",
       "      <td>1.584812</td>\n",
       "      <td>0.124505</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.777890</td>\n",
       "      <td>1.700499</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>2.385502</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.768464</td>\n",
       "      <td>107.430682</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.477420</td>\n",
       "      <td>1.666678</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age       Height       Weight         FCVC          NCP  \\\n",
       "count  2111.000000  2111.000000  2111.000000  2111.000000  2111.000000   \n",
       "mean     24.312600     1.701677    86.586058     2.419043     2.685628   \n",
       "std       6.345968     0.093305    26.191172     0.533927     0.778039   \n",
       "min      14.000000     1.450000    39.000000     1.000000     1.000000   \n",
       "25%      19.947192     1.630000    65.473343     2.000000     2.658738   \n",
       "50%      22.777890     1.700499    83.000000     2.385502     3.000000   \n",
       "75%      26.000000     1.768464   107.430682     3.000000     3.000000   \n",
       "max      61.000000     1.980000   173.000000     3.000000     4.000000   \n",
       "\n",
       "              CH2O          FAF          TUE  \n",
       "count  2111.000000  2111.000000  2111.000000  \n",
       "mean      2.008011     1.010298     0.657866  \n",
       "std       0.612953     0.850592     0.608927  \n",
       "min       1.000000     0.000000     0.000000  \n",
       "25%       1.584812     0.124505     0.000000  \n",
       "50%       2.000000     1.000000     0.625350  \n",
       "75%       2.477420     1.666678     1.000000  \n",
       "max       3.000000     3.000000     2.000000  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_copy.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feature = [feature for feature in df_copy.columns if df_copy[feature].dtypes != 'O']\n",
    "discrete_feature=[feature for feature in numerical_feature if len(df_copy[feature].unique())<25]\n",
    "continuous_feature = [feature for feature in numerical_feature if feature not in discrete_feature]\n",
    "categorical_feature = [feature for feature in df_copy.columns if feature not in numerical_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender',\n",
       " 'family_history_with_overweight',\n",
       " 'FAVC',\n",
       " 'CAEC',\n",
       " 'SMOKE',\n",
       " 'SCC',\n",
       " 'CALC',\n",
       " 'MTRANS',\n",
       " 'NObeyesdad']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gender_map = {'Female':0,'Male':1}\n",
    "family_history_with_overweight_map = {'no':0,'yes':1}\n",
    "FAVC_map = {'no':0,'yes':1}\n",
    "SMOKE_map = {'no':0,'yes':1}\n",
    "SCC_map = {'no':0,'yes':1}\n",
    "CAEC_map = {'no':0, 'Sometimes':1, 'Frequently':2, 'Always':3}\n",
    "CALC_map = {'no':0, 'Sometimes':1, 'Frequently':2, 'Always':3}\n",
    "MTRANS_map = {'Public_Transportation':0, 'Walking':1, 'Automobile':2, 'Motorbike':3, 'Bike':4}\n",
    "NObeyesdad_map = {'Normal_Weight':0, 'Overweight_Level_I':1, 'Overweight_Level_II':2,\n",
    " 'Obesity_Type_I':3, 'Insufficient_Weight':4, 'Obesity_Type_II':5,\n",
    " 'Obesity_Type_III':6}\n",
    "\n",
    "df_copy['Gender'] = df_copy['Gender'].map(gender_map)\n",
    "df_copy['family_history_with_overweight'] = df_copy['family_history_with_overweight'].map(family_history_with_overweight_map)\n",
    "df_copy['FAVC'] = df_copy['FAVC'].map(FAVC_map)\n",
    "df_copy['SMOKE'] = df_copy['SMOKE'].map(SMOKE_map)\n",
    "df_copy['SCC'] = df_copy['SCC'].map(SCC_map)\n",
    "df_copy['CAEC'] = df_copy['CAEC'].map(CAEC_map)\n",
    "df_copy['CALC'] = df_copy['CALC'].map(CALC_map)\n",
    "df_copy['MTRANS'] = df_copy['MTRANS'].map(MTRANS_map)\n",
    "df_copy['NObeyesdad'] = df_copy['NObeyesdad'].map(NObeyesdad_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_copy.drop(\"NObeyesdad\",axis=1)\n",
    "y = df_copy['NObeyesdad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer ## HAndling Missing Values\n",
    "from sklearn.preprocessing import StandardScaler # HAndling Feature Scaling\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "## pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numerical Pipeline\n",
    "num_pipeline=Pipeline(\n",
    "    steps=[\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('scaler',StandardScaler(with_mean=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor=ColumnTransformer([\n",
    "('num_pipeline',num_pipeline,numerical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 16)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(627, 16)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(627,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.DataFrame(preprocessor.fit_transform(X_train),columns=preprocessor.get_feature_names_out())\n",
    "X_test=pd.DataFrame(preprocessor.transform(X_test),columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\himanshu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modal= LogisticRegression()\n",
    "modal.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 43  10   8   0  17   0   0]\n",
      " [ 10  49   8   1   0   0   0]\n",
      " [  1  13  60  22   0   1   0]\n",
      " [  0   0   3  94   0   8   3]\n",
      " [  7   0   0   0  70   0   0]\n",
      " [  0   0   0   1   0  91   0]\n",
      " [  0   0   0   1   0   0 106]] confusion_matrix\n",
      "0.8181818181818182 accuracy_score\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.55      0.62        78\n",
      "           1       0.68      0.72      0.70        68\n",
      "           2       0.76      0.62      0.68        97\n",
      "           3       0.79      0.87      0.83       108\n",
      "           4       0.80      0.91      0.85        77\n",
      "           5       0.91      0.99      0.95        92\n",
      "           6       0.97      0.99      0.98       107\n",
      "\n",
      "    accuracy                           0.82       627\n",
      "   macro avg       0.80      0.81      0.80       627\n",
      "weighted avg       0.81      0.82      0.81       627\n",
      " classification_report\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = modal.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred2),'confusion_matrix')\n",
    "print(accuracy_score(y_test,y_pred2),'accuracy_score')\n",
    "print(classification_report(y_test,y_pred2),'classification_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\himanshu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "0.8181818181818182 accuracy_score\n",
      "Model Training Performance\n",
      "training accuracy 0.8486301369863014\n",
      "===================================\n",
      "\n",
      "\n",
      "RandomForest\n",
      "0.8181818181818182 accuracy_score\n",
      "Model Training Performance\n",
      "training accuracy 0.8376712328767123\n",
      "===================================\n",
      "\n",
      "\n",
      "DecisionTree\n",
      "0.8181818181818182 accuracy_score\n",
      "Model Training Performance\n",
      "training accuracy 1.0\n",
      "===================================\n",
      "\n",
      "\n",
      "svc\n",
      "0.8181818181818182 accuracy_score\n",
      "Model Training Performance\n",
      "training accuracy 0.6746575342465754\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\himanshu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    'RandomForest':RandomForestClassifier(max_depth=4, random_state=0,oob_score=True),\n",
    "    \"DecisionTree\":DecisionTreeClassifier(),\n",
    "    \"svc\": LinearSVC()\n",
    "}\n",
    "trained_model_list=[]\n",
    "model_list=[]\n",
    "accuracy_score_list=[]\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model=list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    #Make Predictions\n",
    "    y_pred=model.predict(X_test)\n",
    "\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print(accuracy_score(y_test,y_pred2),'accuracy_score')\n",
    "    accuracy_score_list.append(accuracy_score(y_test,y_pred2))\n",
    "\n",
    "    print('Model Training Performance')\n",
    "    print('training accuracy',model.score(X_train,y_train))\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('linear_regression', DecisionTreeClassifier()),\n",
    "    ('random_forest', RandomForestClassifier()),\n",
    "    ('gradient_boosting', GradientBoostingClassifier())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_search\n",
      "0.8181818181818182 accuracy_score\n",
      "Model Training Performance\n",
      "training accuracy 0.8294520547945206\n",
      "===================================\n",
      "\n",
      "\n",
      "Bagging_randomforest\n",
      "0.8181818181818182 accuracy_score\n",
      "Model Training Performance\n",
      "training accuracy 0.873972602739726\n",
      "===================================\n",
      "\n",
      "\n",
      "Stacking_regressor\n",
      "0.8181818181818182 accuracy_score\n",
      "Model Training Performance\n",
      "training accuracy 1.0\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models={\n",
    "    # \"grid_search\": GridSearchCV(estimator=RandomForestClassifier, param_grid=param_grid, cv=5),\n",
    "    \"grid_search\": GridSearchCV(DecisionTreeClassifier(), params, cv=5),\n",
    "    'Bagging_randomforest': BaggingClassifier(estimator=RandomForestClassifier(max_depth=4, random_state=0),n_estimators=15, random_state=0),\n",
    "    'Stacking_regressor': StackingClassifier(estimators=estimators, final_estimator=RandomForestClassifier(max_depth=4, random_state=0),cv=5)\n",
    "}\n",
    "trained_model_list=[]\n",
    "model_list=[]\n",
    "accuracy_score_list=[]\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model=list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    #Make Predictions\n",
    "    y_pred=model.predict(X_test)\n",
    "\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print(accuracy_score(y_test,y_pred2),'accuracy_score')\n",
    "    accuracy_score_list.append(accuracy_score(y_test,y_pred2))\n",
    "\n",
    "    print('Model Training Performance')\n",
    "    print('training accuracy',model.score(X_train,y_train))\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
